{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Objective\n",
    "### I'm going to create a logistic regression classifier. And add the normal equation in addition to gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details\n",
    "- Convert from gradient descent to the normal equation\n",
    "- Convert prediction function by wrapping current with sigmoid function\n",
    "- Convert cost function and gradient descent for logistic regression\n",
    "- Regularize my input\n",
    "- Use advanced optimization algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from scipy import special as scipy\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-60-355f69c53e01>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-355f69c53e01>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    x.item(a) = 1 / (1 + math.item(a))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "class LogisticClassifier:\n",
    "    \n",
    "    theta = [0, 0]\n",
    "    alpha = 0.01\n",
    "    epoch = 300\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, theta_size=2, alpha=0.01, epoch=5, threshold=0.5):\n",
    "        self.theta = [0] * theta_size\n",
    "        self.alpha = alpha\n",
    "        self.epoch = epoch\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    \n",
    "    # Given input x of length of j(theta_size-1)\n",
    "    # Returns m(#examples) x 1 matrix of yhat\n",
    "    def predict_linear(self, x):\n",
    "        x = np.insert(x, 0, 1, axis=1)\n",
    "        x = np.matrix(x)\n",
    "        theta = np.matrix(self.theta)\n",
    "        theta = theta.T\n",
    "        return np.matmul(x, theta)\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        for a in range(x.shape[5]):\n",
    "                x.item(a) = 1 / (1 + math.item(a))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # Given training data Xtr and Ytr\n",
    "    def train(self, Xtr, Ytr):        \n",
    "        Ytr = np.matrix(Ytr)\n",
    "        Xtr = np.matrix(Xtr)\n",
    "        Ytr = Ytr.T\n",
    "        self.gradient_des(Xtr, Ytr)\n",
    "        \n",
    "        \n",
    "    # Given predictions(Yhat) and correct labels(Yte)\n",
    "    # Returns squared error\n",
    "    def cost_fcn(self, Yhat, Yte):\n",
    "        squared_error = (Yhat - Yte)**2\n",
    "        b = 1/(Yhat.size*2)\n",
    "        return b * np.sum(squared_error, 0)\n",
    "    \n",
    "    \n",
    "    # Given training data Xtr and Ytr\n",
    "    # Graphs error over iterations of gradient descent\n",
    "    def gradient_des(self, Xtr, Ytr):\n",
    "#         j2 = np.zeros(self.epoch)\n",
    "#         i2 = np.zeros(self.epoch)\n",
    "        for i in range(0, self.epoch):\n",
    "            Yhat = self.predict_linear(Xtr)\n",
    "#             print(Yhat)\n",
    "            Yhat = self.sigmoid(Yhat)\n",
    "            print(Yhat)\n",
    "            Ytr = np.matrix(Ytr)\n",
    "            Xtr = np.matrix(Xtr)\n",
    "            \n",
    "            self.theta -= self.alpha * (Yhat - Ytr) * Xtr\n",
    "#             j2[i] = self.cost_fcn(Yhat.A1, Ytr.A1)  # .A1 turns matrix -> array\n",
    "#             i2[i] = i\n",
    "#         plt.xlabel(\"Iterations\")\n",
    "#         plt.ylabel(\"Error\")\n",
    "#         plt.plot(i2, j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n",
      "[[0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (5,1) and (5,1) not aligned: 1 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f15b50e03dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-21373e6ce7c0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, Xtr, Ytr)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mXtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mYtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_des\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-21373e6ce7c0>\u001b[0m in \u001b[0;36mgradient_des\u001b[0;34m(self, Xtr, Ytr)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mXtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mYhat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mXtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;31m#             j2[i] = self.cost_fcn(Yhat.A1, Ytr.A1)  # .A1 turns matrix -> array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#             i2[i] = i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (5,1) and (5,1) not aligned: 1 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "# theta = []\n",
    "\n",
    "X = [[10], [20], [30], [40], [50], [60], [15]]\n",
    "Y = [1, 1, 1, 0, 0, 1]\n",
    "Xtr = X[0:5]\n",
    "Ytr = Y[0:5]\n",
    "Xte = X[5:6]\n",
    "Yte = Y[5:6]\n",
    "\n",
    "model = LogisticClassifier()\n",
    "model.train(Xtr, Ytr)\n",
    "print(model.predict_logistic(Xte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok... compared to Octave this is quite impractical. I'm going to switch over to tensorflow. This sigmoid function that can't be applied to a matrix in a vectorized fashion is lame. \n",
    "\n",
    "### Going to expand it to another repo, then come back here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, just learned TensorFlow. Let's do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier:\n",
    "    \n",
    "    weights = tf.Variable(tf.random_uniform([1,2]), \n",
    "                          tf.float32)\n",
    "    \n",
    "    learning_rate = tf.random_uniform(maxval=0.01, \n",
    "                                      minval=0.0001,\n",
    "                                      shape=[0],\n",
    "                                      dtype=tf.float32)\n",
    "    \n",
    "    epoch = tf.random_uniform(maxval=10, \n",
    "                              minval=300, \n",
    "                              shape=[0],\n",
    "                              dtype=tf.int32)\n",
    "\n",
    "    # Initalizes parameters\n",
    "    def init(self, new_weights, new_alpha, new_epoch):\n",
    "        self.theta = new_weights\n",
    "        self.alpha = new_alpha\n",
    "        self.epoch = new_epoch    \n",
    "    \n",
    "    # Given Xhat (Examples x Features)\n",
    "    # Where Xhat has a rank of 2\n",
    "    # Returns Yhat (Labels x 1)\n",
    "    def predict(self, Xhat):\n",
    "        ones = tf.ones([tf.shape(Xhat)[0], 1], tf.float32)\n",
    "        x = tf.concat([ones, Xhat], 1)\n",
    "        x = tf.matmul(x, tf.transpose(self.weights))\n",
    "        return x\n",
    "#         x = np.insert(Xhat, 0, 1, axis=1)\n",
    "#         x = np.matrix(x)\n",
    "#         theta = np.matrix(self.theta)\n",
    "#         theta = theta.T\n",
    "#         return np.matmul(x, theta)\n",
    "\n",
    "    \n",
    "#     def sigmoid(self, x):\n",
    "#         for a in range(x.shape[5]):\n",
    "#                 x.item(a) = 1 / (1 + math.item(a))\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "#     # Given training data Xtr and Ytr\n",
    "#     def train(self, Xtr, Ytr):        \n",
    "#         Ytr = np.matrix(Ytr)\n",
    "#         Xtr = np.matrix(Xtr)\n",
    "#         Ytr = Ytr.T\n",
    "#         self.gradient_des(Xtr, Ytr)\n",
    "        \n",
    "        \n",
    "#     # Given predictions(Yhat) and correct labels(Yte)\n",
    "#     # Returns squared error\n",
    "#     def cost_fcn(self, Yhat, Yte):\n",
    "#         squared_error = (Yhat - Yte)**2\n",
    "#         b = 1/(Yhat.size*2)\n",
    "#         return b * np.sum(squared_error, 0)\n",
    "    \n",
    "    \n",
    "#     # Given training data Xtr and Ytr\n",
    "#     # Graphs error over iterations of gradient descent\n",
    "#     def gradient_des(self, Xtr, Ytr):\n",
    "# #         j2 = np.zeros(self.epoch)\n",
    "# #         i2 = np.zeros(self.epoch)\n",
    "#         for i in range(0, self.epoch):\n",
    "#             Yhat = self.predict_linear(Xtr)\n",
    "# #             print(Yhat)\n",
    "#             Yhat = self.sigmoid(Yhat)\n",
    "#             print(Yhat)\n",
    "#             Ytr = np.matrix(Ytr)\n",
    "#             Xtr = np.matrix(Xtr)\n",
    "            \n",
    "#             self.theta -= self.alpha * (Yhat - Ytr) * Xtr\n",
    "#             j2[i] = self.cost_fcn(Yhat.A1, Ytr.A1)  # .A1 turns matrix -> array\n",
    "#             i2[i] = i\n",
    "#         plt.xlabel(\"Iterations\")\n",
    "#         plt.ylabel(\"Error\")\n",
    "#         plt.plot(i2, j2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "[[0.9666078 ]\n",
      " [0.87346   ]\n",
      " [0.92186165]\n",
      " [0.87489086]\n",
      " [0.90299195]]\n",
      "\n",
      "Weights\n",
      "[[0.870736   0.10043514]]\n",
      "\n",
      "Prediction\n",
      "[[0.9042882 ]\n",
      " [0.8890509 ]\n",
      " [0.95139885]\n",
      " [0.9523581 ]\n",
      " [0.9482819 ]]\n"
     ]
    }
   ],
   "source": [
    "# TESTING PREDICT\n",
    "model = LinearClassifier()\n",
    "Xhat = tf.random_uniform([5,1], dtype=tf.float32)\n",
    "Xhat = model.predict(Xhat)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Input\")\n",
    "    r = Xhat\n",
    "    p = tf.Print(r, [r])\n",
    "    print(sess.run(p))\n",
    "    \n",
    "    print(\"\\nWeights\")\n",
    "    r = model.weights\n",
    "    p = tf.Print(r, [r])\n",
    "    print(sess.run(p))\n",
    "    \n",
    "    print(\"\\nPrediction\")\n",
    "    r = Xhat\n",
    "    p = tf.Print(r, [r])\n",
    "    print(sess.run(p))\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform_11:0\", shape=(1,), dtype=float32)\n",
      "[0.23018432]\n"
     ]
    }
   ],
   "source": [
    "# PRINTING TENSOR\n",
    "with tf.Session() as sess:\n",
    "    r = tf.random_uniform([1])\n",
    "    p = tf.Print(r, [r])\n",
    "    print(r)\n",
    "    print(sess.run(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
